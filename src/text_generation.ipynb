{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD_55cOxLkAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab43c986-ec8d-405d-99b9-751f9db64fae"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('175b_samples.jsonl', 'https://raw.githubusercontent.com/openai/gpt-3/master/175b_samples.jsonl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/openai/gpt-3/master/175b_samples.jsonl\n",
            "4096000/4092490 [==============================] - 0s 0us/step\n",
            "4104192/4092490 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1DVW647CQV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8664a4-b01c-491e-90f5-bdc0f82f4016"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavnuByVymwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96df0ab6-e243-474a-88e9-6fe273c452d1"
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 4061374 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duhg9NrUymwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3a33f4-1ae0-4ab2-abd6-3e554c346c18"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Glacier Ridge Christian School\\n\\nGlacier Ridge Christian School is a private Christian school in Johnstown, Ohio. It was founded in the fall of 1999 by Gary and Tammy Smith.\\n\\nThe school started with just 13 students in grades 5-8. By the end of t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCgQBRVymwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc54639-4f55-4f80-8d3d-7b0691d87ce0"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "674 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a86OoYtO01go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f3bb92-b38c-4cf9-9f54-06557a8ab27c"
      },
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GMlCe3qzaL9"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLv5Q_2TC2pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194c5de1-f5cf-43bc-8569-dd04c272aff5"
      },
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[67, 68, 69, 70, 71, 72, 73], [90, 91, 92]]>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2m3mqkDjRj"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2GCh0ySD44s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1562f866-3824-4ab1-df9e-e8da02124834"
      },
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxYI-PeltqKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc8ea02-7487-4fdd-8de5-192c527c8ea6"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5apvBDn9Ind"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UopbsKi88tm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10acc031-0dfc-40ef-bb41-db66dfda625d"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4061374,), dtype=int64, numpy=array([ 4, 41, 78, ..., 14,  4,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmxrYDCTy-eL"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjH5v45-yqqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e238f55f-5811-4539-db18-4d279e287c25"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\n",
            "G\n",
            "l\n",
            "a\n",
            "c\n",
            "i\n",
            "e\n",
            "r\n",
            " \n",
            "R\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-G2oaTxy6km"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpdjRO2CzOfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02825c49-5c78-4d2f-e9ef-8f175483fe5b"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\"' b'G' b'l' b'a' b'c' b'i' b'e' b'r' b' ' b'R' b'i' b'd' b'g' b'e'\n",
            " b' ' b'C' b'h' b'r' b'i' b's' b't' b'i' b'a' b'n' b' ' b'S' b'c' b'h'\n",
            " b'o' b'o' b'l' b'\\\\' b'n' b'\\\\' b'n' b'G' b'l' b'a' b'c' b'i' b'e' b'r'\n",
            " b' ' b'R' b'i' b'd' b'g' b'e' b' ' b'C' b'h' b'r' b'i' b's' b't' b'i'\n",
            " b'a' b'n' b' ' b'S' b'c' b'h' b'o' b'o' b'l' b' ' b'i' b's' b' ' b'a'\n",
            " b' ' b'p' b'r' b'i' b'v' b'a' b't' b'e' b' ' b'C' b'h' b'r' b'i' b's'\n",
            " b't' b'i' b'a' b'n' b' ' b's' b'c' b'h' b'o' b'o' b'l' b' ' b'i' b'n'\n",
            " b' ' b'J' b'o'], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO32cMWu4a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4acbbf-a9e3-4428-c057-7343c8971b1e"
      },
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\"Glacier Ridge Christian School\\\\n\\\\nGlacier Ridge Christian School is a private Christian school in Jo'\n",
            "b'hnstown, Ohio. It was founded in the fall of 1999 by Gary and Tammy Smith.\\\\n\\\\nThe school started with'\n",
            "b' just 13 students in grades 5-8. By the end of the first year, the school had grown to 65 students in'\n",
            "b' those same grades. As the school has continued to grow, so has the number of teachers.\\\\n\\\\nBy the yea'\n",
            "b'r 2009, Glacier Ridge had expanded to offer a preschool through 12th grade education, and the school '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxbDTJTw5u_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8cac97-5ad0-4c98-e67d-11ce6cbfef55"
      },
      "source": [
        "split_input_target(list(\"Ded Security\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['D', 'e', 'd', ' ', 'S', 'e', 'c', 'u', 'r', 'i', 't'],\n",
              " ['e', 'd', ' ', 'S', 'e', 'c', 'u', 'r', 'i', 't', 'y'])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9iKPXkw5xwa"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b5d039-774e-413e-d214-aff003e7a376"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'\"Glacier Ridge Christian School\\\\n\\\\nGlacier Ridge Christian School is a private Christian school in J'\n",
            "Target: b'Glacier Ridge Christian School\\\\n\\\\nGlacier Ridge Christian School is a private Christian school in Jo'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2pGotuNzf-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944774b7-1f42-4a5a-8d3c-e1b9bb3f0d49"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## Build The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "This section defines the model as a `keras.Model` subclass (For details see [Making new Layers and Models via subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models)). \n",
        "\n",
        "This model has three layers:\n",
        "\n",
        "* `tf.keras.layers.Embedding`: The input layer. A trainable lookup table that will map each character-ID to a vector with `embedding_dim` dimensions;\n",
        "* `tf.keras.layers.GRU`: A type of RNN with size `units=rnn_units` (You can also use an LSTM layer here.)\n",
        "* `tf.keras.layers.Dense`: The output layer, with `vocab_size` outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "embedding_dim = 256\n",
        "\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj8HQ2w8z4iO"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX58Xj9z47Aw"
      },
      "source": [
        "model = MyModel(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-_70kKAPrPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274cc3b9-666f-43c6-8431-a3f0e5c0a68f"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 675) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eabd3abe-a333-456d-c9b5-f1730f6a0697"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     multiple                  172800    \n",
            "                                                                 \n",
            " gru_2 (GRU)                 multiple                  3938304   \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  691875    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,802,979\n",
            "Trainable params: 4,802,979\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqFMUQc_UFgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc78eb40-940f-423e-955b-e5aacb221315"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([629,  93, 350, 508, 143, 148,  71, 242, 656, 366, 448, 260, 406,\n",
              "       507, 319, 366,  30,  54, 583,  68, 202, 494, 568, 669, 587, 435,\n",
              "       297, 149, 430, 171, 673,  42, 651, 463, 227, 237,  43, 563, 599,\n",
              "        47, 549, 237,  30, 590,  16, 213, 272, 639, 243,  71, 334, 672,\n",
              "       408, 630, 468, 151, 232, 661, 388, 468, 441, 206, 484, 441,  56,\n",
              "       313, 569,  28, 426, 155, 175, 188,  88, 510, 429, 567, 486, 421,\n",
              "       268,  95, 170, 148, 344, 194,  19, 599, 194, 413, 505,  94, 648,\n",
              "       204, 186,  78, 469, 315, 579, 237, 102, 324])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWcFwPwLSo05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8b6cbc-d8c5-4b27-c686-222a4d974a5a"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'f it you want to read. When I read the story in the paper, I didn\\xe2\\x80\\x99t try to understand the process by'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\xe8\\xbf\\x91{\\xe5\\x8d\\x88\\xe6\\xb0\\xb8\\xc3\\xad\\xc3\\xb3e\\xe2\\x86\\x91\\xe9\\x9b\\xbb\\xe5\\x92\\x8c\\xe6\\x87\\x82\\xe3\\x82\\xaa\\xe5\\xae\\xb9\\xe6\\xaf\\x94\\xe4\\xbd\\xbf\\xe5\\x92\\x8c<T\\xe8\\x83\\xbdb\\xd0\\xa1\\xe6\\x9d\\x82\\xe7\\xb6\\xb2\\xef\\xbc\\x88\\xe8\\x8b\\xa5\\xe5\\xbc\\xb7\\xe4\\xba\\x86\\xc3\\xb4\\xe5\\xbb\\x8a\\xc5\\x81\\xef\\xbf\\xbdH\\xe9\\x98\\xbb\\xe6\\x8d\\x9f\\xe2\\x80\\x8e\\xe2\\x80\\xa6I\\xe7\\xae\\xa1\\xe8\\xa6\\xa7M\\xe7\\xa0\\xb4\\xe2\\x80\\xa6<\\xe8\\x99\\x9a.\\xd0\\xb9\\xe3\\x83\\xa9\\xe9\\x81\\x93\\xe2\\x86\\x92e\\xe5\\x86\\x99\\xef\\xbc\\x9a\\xe5\\xaf\\xbc\\xe8\\xbf\\x98\\xe6\\x8f\\x92\\xc3\\xb6\\xe2\\x80\\x99\\xe9\\xa2\\x86\\xe5\\xa4\\xa7\\xe6\\x8f\\x92\\xe6\\x80\\xa7\\xd0\\xb1\\xe6\\x98\\xaf\\xe6\\x80\\xa7V\\xe4\\xbc\\x97\\xe7\\xba\\xa7:\\xe5\\xba\\x8f\\xc3\\xbb\\xc5\\x8d\\xc5\\xbav\\xe6\\xb2\\xa1\\xe5\\xba\\xa6\\xe7\\xb4\\xaf\\xe6\\x9c\\x80\\xe5\\xb8\\xb8\\xe3\\x83\\x8a}\\xc4\\xbe\\xc3\\xb3\\xe5\\x8a\\xa8\\xcc\\x811\\xe8\\xa6\\xa7\\xcc\\x81\\xe5\\xb1\\x81\\xe6\\xae\\xb5|\\xe9\\x97\\xae\\xd0\\xaf\\xc5\\xafl\\xe6\\x94\\xaf\\xe4\\xbd\\x86\\xe8\\x80\\x8c\\xe2\\x80\\xa6\\xc2\\xaa\\xe5\\x81\\x9a'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOeWdgxNFDXq"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HrXTACTdzY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2215be0b-5905-450b-d1bc-b089dd9d76b0"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 675)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         6.5158863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAJfS5YoFiHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8524a71b-1e5d-4593-f684-55b3ea5de1fe"
      },
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "675.79266"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6fWTriUZP-n"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK-hmKjYVoll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9822651b-d1a7-48c1-fd13-e49771b2ab0e"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "628/628 [==============================] - 99s 153ms/step - loss: 2.3335\n",
            "Epoch 2/20\n",
            "628/628 [==============================] - 97s 152ms/step - loss: 1.6380\n",
            "Epoch 3/20\n",
            "628/628 [==============================] - 97s 153ms/step - loss: 1.4357\n",
            "Epoch 4/20\n",
            "628/628 [==============================] - 98s 153ms/step - loss: 1.3365\n",
            "Epoch 5/20\n",
            "628/628 [==============================] - 97s 152ms/step - loss: 1.2703\n",
            "Epoch 6/20\n",
            "628/628 [==============================] - 97s 151ms/step - loss: 1.2190\n",
            "Epoch 7/20\n",
            "628/628 [==============================] - 97s 152ms/step - loss: 1.1778\n",
            "Epoch 8/20\n",
            "628/628 [==============================] - 98s 153ms/step - loss: 1.1422\n",
            "Epoch 9/20\n",
            "628/628 [==============================] - 97s 152ms/step - loss: 1.1123\n",
            "Epoch 10/20\n",
            "628/628 [==============================] - 97s 153ms/step - loss: 1.0873\n",
            "Epoch 11/20\n",
            "628/628 [==============================] - 98s 153ms/step - loss: 1.0664\n",
            "Epoch 12/20\n",
            "628/628 [==============================] - 97s 152ms/step - loss: 1.0489\n",
            "Epoch 13/20\n",
            "628/628 [==============================] - 98s 153ms/step - loss: 1.0403\n",
            "Epoch 14/20\n",
            "628/628 [==============================] - 99s 154ms/step - loss: 1.0291\n",
            "Epoch 15/20\n",
            "628/628 [==============================] - 98s 153ms/step - loss: 1.0198\n",
            "Epoch 16/20\n",
            "628/628 [==============================] - 97s 152ms/step - loss: 1.0143\n",
            "Epoch 17/20\n",
            "628/628 [==============================] - 97s 152ms/step - loss: 1.0122\n",
            "Epoch 18/20\n",
            "628/628 [==============================] - 98s 153ms/step - loss: 1.0135\n",
            "Epoch 19/20\n",
            "628/628 [==============================] - 97s 153ms/step - loss: 1.0199\n",
            "Epoch 20/20\n",
            "628/628 [==============================] - 98s 153ms/step - loss: 1.0293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSBU1tHmlUSs"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        " \n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqMOuDutnOxK"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST7PSyk9t1mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64698b1f-5c61-4b25-c47f-a0b655a52cfa"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Model prompt:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model prompt: Wathing Service Lings and GAP coming Patsia States Northure and Pantle School name\\n\\nKanik Gambrode zokkee\\n\\n\\n\\nCake as Iraq's company\\n\\nCassing Wilsons Tools\\n\\nB&W by alword Visiel Mccenico he bordere\\n\\n\\n\\nReddoire : 9 â‚¬\\n\\n\\n**3.9grating!\\n\\nRembected States (HCLP) Power Players [ for Scott. The song at the Solement Donsky School for\\n\\nThese particle ancoman Sage Pages report is lying about the higher-hit-alcone holding company, with Runsiap to file the Gip-of-30 children of Tomby. It was the first movie of the sea as another choose fee in Learning causes of money to all the shareholders, makes to write by this first risk of discrimination.\\n\\nBut there are many disorder to the Chinatowic Stephen Matt sport of Nigerca's 'made you how long battle art farms for Frangfights and may sink by joining and surprising Him Knee.[3] There are allows for the Matthew and training effectively, but not without against a controller when it still spend God (adows you two things that are told \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.8827645778656006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkLu7Y8UCMT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2022ccbc-dcb9-4696-d41b-14990e478548"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['TESTE:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b\"TESTE:\\\\n\\\\n(A) (A Catchar de Jerecone, Jone Bander\\\\n\\\\nThe Em Doutt showed that Trump is a great red by the Hampathy (nigeo Kates. This maximum sensey having want an unhappy with the highest life with all the tweets stay in a corporatorium on the Japanese exer-imperiable. So if you\\xe2\\x80\\x99re driffy.\\\\n\\\\nWhy public software gays aren\\xe2\\x80\\x99t in your sexual parameters. This will vocal clicking and vitamine is similar to easily trip to ash.\\\\n\\\\n\\\\n\\\\nDoes anything you\\xe2\\x80\\x99ll fail together a treat few other concerns outside. Not just in this chain as you are wharqued and didn\\xe2\\x80\\x99t get any what to dafe to figure. And you could emotion, and that of the hord, she always questions we all window science. Vandoone es una forma de college, acquass, a majority dans le campus de r\\xc3\\xa9dactieline. Just qui con historie, ma C'LTo, Ammus Lomishi is locate.\\\\n\\\\n\\xe2\\x80\\xa2 Source: Croteceatic dots of CNN.V Agent (UBC), 1998.7\\\\n\\\\nJane 4, 2018 this time, there was established in the following declines in authenting spot by the battery historical warn\"], shape=(1,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.9098758697509766\n"
          ]
        }
      ]
    }
  ]
}